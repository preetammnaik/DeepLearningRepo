{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "66iYIwqiB_yn"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras.datasets import mnist"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the data\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "# Normalize pixel values\n",
        "x_train = x_train / 255.0\n"
      ],
      "metadata": {
        "id": "TZFwTDGJCPRQ"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_shape = x_train.shape\n",
        "\n",
        "print(f\"There are {data_shape[0]} examples with shape ({data_shape[1]}, {data_shape[2]})\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IsfURuWeCt_-",
        "outputId": "adb6039d-0f7d-47fc-dbdb-1c4de5425f21"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 60000 examples with shape (28, 28)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class myCallback(tf.keras.callbacks.Callback):\n",
        "        # Define the correct function signature for on_epoch_end\n",
        "        def on_epoch_end(self, epoch, logs={}):\n",
        "            if logs.get('accuracy') is not None and logs.get('accuracy') > 0.99:                 \n",
        "                print(\"\\nReached 99% accuracy so cancelling training!\")\n",
        "                # Stop training once the above condition is met\n",
        "                self.model.stop_training = True"
      ],
      "metadata": {
        "id": "wlL-QNbQCcZJ"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_mnist(x_train, y_train):\n",
        "\n",
        "    ### START CODE HERE\n",
        "    \n",
        "    # Instantiate the callback class\n",
        "    callbacks = myCallback()\n",
        "    \n",
        "    # Define the model\n",
        "    model = tf.keras.models.Sequential([         \n",
        "        tf.keras.layers.Flatten(),\n",
        "        tf.keras.layers.Dense(512, activation = tf.nn.relu),\n",
        "        tf.keras.layers.Dense(10,activation=tf.nn.softmax)\n",
        "        \n",
        "        \n",
        "    ]) \n",
        "    \n",
        "    # Compile the model\n",
        "    model.compile(optimizer='adam',                   \n",
        "                  loss='sparse_categorical_crossentropy',                   \n",
        "                  metrics=['accuracy'])     \n",
        "    \n",
        "    # Fit the model for 10 epochs adding the callbacks\n",
        "    # and save the training history\n",
        "    history = model.fit(x_train, y_train, epochs=10, callbacks=[callbacks])\n",
        "\n",
        "    ### END CODE HERE\n",
        "\n",
        "    return history"
      ],
      "metadata": {
        "id": "5HiUQexwC07m"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hist = train_mnist(x_train, y_train)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IKZahZuaC314",
        "outputId": "d6edb73b-093d-431c-fbdc-4ae718d5cb05"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "1875/1875 [==============================] - 16s 8ms/step - loss: 0.2004 - accuracy: 0.9407\n",
            "Epoch 2/10\n",
            "1875/1875 [==============================] - 15s 8ms/step - loss: 0.0809 - accuracy: 0.9749\n",
            "Epoch 3/10\n",
            "1875/1875 [==============================] - 15s 8ms/step - loss: 0.0535 - accuracy: 0.9836\n",
            "Epoch 4/10\n",
            "1875/1875 [==============================] - 15s 8ms/step - loss: 0.0369 - accuracy: 0.9883\n",
            "Epoch 5/10\n",
            "1873/1875 [============================>.] - ETA: 0s - loss: 0.0278 - accuracy: 0.9912\n",
            "Reached 99% accuracy so cancelling training!\n",
            "1875/1875 [==============================] - 16s 8ms/step - loss: 0.0278 - accuracy: 0.9912\n"
          ]
        }
      ]
    }
  ]
}